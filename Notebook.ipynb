{"cells":[{"cell_type":"markdown","metadata":{"id":"_387YTJGMbTr"},"source":["<center> <h2>TRƯỜNG ĐẠI HỌC CÔNG NGHỆ THÔNG TIN</h2>\n","<h1>CS114.O11 - MÁY HỌC </h1>\n","<h1>ĐỒ ÁN CUỐI KÌ</h1>\n","<h1>TRÍCH XUẤT THÔNG TIN TỪ ẢNH CHỤP CHỨNG CHỈ TOEIC </h1></center>"]},{"cell_type":"markdown","metadata":{"id":"BaDc5eFTMbTy"},"source":["# 1. GIỚI THIỆU"]},{"cell_type":"markdown","metadata":{"id":"nUErXzY7MbT0"},"source":["- Môn học: Máy học - Machine Learning\n","- Lớp:  CS114.O11\n","- Năm học : 2023 - 2024\n","- Giảng viên:\n","    -   PGS.TS. Lê Đình Duy\n","    -   ThS. Phạm Nguyễn Trường An\n","- Thành viên nhóm:\n","    - Nguyễn Phú Trung: 21521592\n","    - Hoàng Hải Anh: 21521819   \n","    - Trương Khánh Long: 21521750"]},{"cell_type":"markdown","metadata":{"id":"9NmOlEUEMbT1"},"source":["# 2. Mô tả bài toán:\n","- Đề tài nghiên cứu tập trung vào mục tiêu tự động trích xuất thông tin từ hình ảnh chứng chỉ TOEIC.\n","- Input: Hình ảnh chụp chứng chỉ chính diện, rõ nét, thể hiện đầy đủ các viền của chứng chỉ.\n","- Output: Các thông tin trên chứng chỉ: tên, ngày thi, ngày hết hạn chứng chỉ, điểm từng thành phần (nghe, nói, đọc, viết). Không trích xuất ID và ngày sinh vì lí do bảo mật.\n","- Ngữ cảnh ứng dụng: Hỗ trợ trích xuất thông tin của thí sinh trên chứng chỉ một cách nhanh chóng với số lượng lớn, nhằm giảm thời gian nhập liệu, xác nhận tính chính xác, khả năng đáp ứng tiêu chuẩn được qui ước hoặc đặt ra (VD: xác nhận thí sinh đáp ứng đủ điểm để đáp ứng việc ra trường/ trích xuất thông tin để liên hệ xác thực chứng chỉ là hợp lệ với bên cung cấp (thường là IIG))."]},{"cell_type":"markdown","metadata":{"id":"ukRhk_7GMbT1"},"source":["# 3. Mô tả bộ dữ liệu"]},{"cell_type":"markdown","metadata":{"id":"7dWv0NjWMbT2"},"source":["## 3.1 Bộ dữ liệu và cách thu thập:\n","+ Các hình ảnh chứng chỉ được thu thập thông qua liên hệ và cho phép bởi trung tâm Anh ngữ Dopassion\n","+ Bao gồm các hình ảnh chụp chứng chỉ Toeic của học viên với các hình ảnh xen lẫn giữa rõ nét và bị làm mờ một số thông tin, trong đó:\n","    + Toeic Nói - Viết : 77 ảnh - Ex: <br>\n","    ![SW](./example2.png)\n","    <br></br>\n","    + Toeic Nghe - Đọc  : 84 ảnh - Ex: <br>\n","    ![LR](./example1.png)\n","+ Mỗi hình ảnh chứng chỉ chứa các thông tin về tên, điểm số (nghe, đọc, nói, viết), ngày thi, ngày hết hạn. Các thông tin về ID và ngày sinh không được thực hiện trích xuất.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_5WspAsYMbT3"},"source":["## 3.2 Các thao tác tiền xử lí dữ liệu"]},{"cell_type":"markdown","metadata":{"id":"4n0CuE52MbT3"},"source":["+ Toàn bộ data, pipeline được lưu trữ trong một folder drive duy nhất.\n","+ Thực hiện loại bỏ các hình ảnh chứng chỉ bị trùng lặp hoặc bị lỗi như: quá mờ, bị che khuất,..\n","+ Sử dụng Label Studio để tiến hành gán nhãn cho từng ảnh một cách thủ công. Quá trình label sẽ xác định các bounding box tại nơi chứa thông tin cần trích xuất tương ứng. Các đặc trưng thu được sẽ được phân tích tại phần Feature Engineer (4.1)\n","+ Sau khi gán nhãn và xuất kết quả, sẽ thu được folder chứa các images và file .txt chứa tọa độ của từng bounding box của hình ảnh tương ứng.\n","+ Tiếp theo là phân chia bộ dữ liệu sau khi thực hiện tiền xử lí."]},{"cell_type":"markdown","metadata":{"id":"O2cAHdUJMbT4"},"source":["## 3.3 Phân chia dataset\n","- Bên trong dataset sẽ gồm có file images và labels:\n","    - Images: chứa 3 tệp train, val, test, bên trong chứa các ảnh chứng chỉ Toeic với số lượng như sau:\n","        - Train: 137 ảnh\n","        - Val: 24 ảnh\n","        - Test: 19 ảnh\n","    - Labels: chứa các file .txt với nội dung là tọa độ của các bounding box dưới dạng ID, x, y, x, y (Mô tả ở phần 4.1) với thứ tự và tên file giống với file ảnh tương ứng trong folders Images trên\n","        - Train: 137 files\n","        - Val: 24 files\n","        - Test: 19 files\n"]},{"cell_type":"markdown","metadata":{"id":"XKALRF4ZMbT5"},"source":["# 4. Mô tả đặc trưng"]},{"cell_type":"markdown","metadata":{"id":"-2crX_MtMbT6"},"source":["### 4.1 Feature Engineering"]},{"cell_type":"markdown","metadata":{"id":"LP-nBRk0MbT6"},"source":["+ Toàn bộ data, pipelines được lưu trữ trong một folder drive duy nhất.\n","+ Các bước thực hiện tạo lập bounding box và xác định các feauture cần trích xuất:\n","    + Sử dụng Label Studio để tiến hành gán nhãn cho từng ảnh một cách thủ công. Quá trình label sẽ xác định các bounding box tại nơi chứa thông tin cần trích xuất tương ứng\n","    ![LR](./example3.png)\n","    + Sau khi gán nhãn và xuất kết quả, sẽ thu được 2 tệp, trong đó chứa các file với tên giống nhau và khác ở phần định dạng:\n","        + Tệp chứa các file .txt, mỗi file sẽ chứa thông tin về ID và tọa độ của box tương ứng với định dạng x y x y với giá trị dạng thập phân từ 0 đến 1. Trong đó x y đầu tiên tương ứng với tọa độ góc trên bên trái và x y phía sau tương ứng với tọa độ góc dưới bên phải của bounding box.\n","        ![LR](./example3-1.png)\n","        + Tệp chứa các hình ảnh đã đăng tải với các bounding box đã được trực quan.\n","    + Tạo file mydata.yaml chứa thông tin về:\n","        + path: đường dẫn đến thư mục chứa dataset\n","        + train: đường dẫn đến thư mục chứa train dataset\n","        + val: đường dẫn đến thư mục chứa test dataset\n","        + names: chứa thông tin về ID number và name tương ứng với định dạng \"ID: name\"\n","+ Thực hiện xử lí các hình ảnh bên trong bounding box nhằm giúp nâng cao khả năng trích xuất thông tin từ các box:\n","    + Xác định vùng quan trọng (vùng chứa dữ liệu cần lấy trong bounding box)\n","    + Chuyển đổi vùng quan trọng từ dạng mảng các pixel sang ảnh dạng grayscale bằng hàm convert(\"L\")\n","    + Áp dụng bộ lọc giảm nhiễu, làm mịn ảnh\n","    + Tăng cường độ tương phản để làm nổi bật văn bản trong ảnh"]},{"cell_type":"markdown","metadata":{"id":"6ga4ULkcMbT6"},"source":["### 4.2 Data Processing Pipeline"]},{"cell_type":"markdown","metadata":{"id":"OlAUGLAYMbT7"},"source":["+ Hình ảnh chứng chỉ sau khi được gán nhãn sẽ được phân chia vào các tệp train - val - test:\n","    + Dữ liệu trong tệp train (bao gồm ảnh đã trực quan các box và file chứa thông tin tọa độ các box) sẽ được đưa vào huấn luyện thông qua việc đọc dữ liệu từ các đường dẫn được cấu hình bên trong file mydata.yaml. Sau khi huấn luyện, 2 model best.pt và last.pt sẽ được lưu trữ một cách tự động ở đường dẫn \"/content/runs/detect/train/weight \". Ở đây, nhóm em sử dụng model best.pt.\n","    + Dữ liệu trong tập val sẽ được dùng cho mục đích cấu hình căn chỉnh các box để kiểm tra và điều chỉnh để model có thể nhận diện đúng các vị trí chứa thông tin cần trích xuất trên chứng chỉ.\n","    + Dữ liệu trong tập test sẽ dùng để kiểm tra mô hình dựa vào model best.pt được train ở trên và dựa vào đó để đánh giá mô hình.\n","+ Hình ảnh sau khi được nhận diện (chứa các thông tin cần trích xuất) vẫn còn bị nhiễu -> cần tiến hành loại bỏ nhiễu, tăng cường tương phản,... -> làm nổi bật phần văn bản cần trích xuất.\n","+ Sử dụng pytesseract và easy_ocr để tiến hành nhận diện văn bản trên các hình ảnh trong các box vừa được xử lí trên.\n","+ Lưu trữ nội dung văn bản đã trích xuất từ ảnh chứng chỉ vào một dataframe với các cột (Name, Listening, Reading, Speaking, Writing, Test_date, Valid_date, File_name) để có thể thực hiện xuất dữ liệu hoặc tiến hành đánh giá model."]},{"cell_type":"markdown","metadata":{"id":"KJayeL-HMbT7"},"source":["# 5. Mô tả thuật toán máy học"]},{"cell_type":"markdown","metadata":{"id":"fN7UMZuRMbT7"},"source":["Train model:"]},{"cell_type":"markdown","metadata":{"id":"gyadk_aqMbT7"},"source":["- Yolov8: là thuật toán thị giác máy tính được sử dụng để phát hiện đối tượng dựa trên convolutional neural network (CNN) với đầu vào là hình ảnh.\n","- Cách hoạt động:\n","    + Đầu tiên, YOLOv8 chia ảnh thành một lưới các ô.\n","    + Đối với mỗi ô, YOLOv8 sẽ dự đoán:\n","        + Loại đối tượng có thể có trong ô đó.\n","        + Tọa độ của bounding box bao quanh đối tượng đó.\n","        + Độ tự tin cho bounding box.\n","    + Các bounding box có độ tự tin cao hơn một ngưỡng nhất định sẽ được coi là chứa đối tượng thật sự\n","- Điểm vượt trội: tốc độ và độ chính xác cao, sự linh hoạt khi có thể nhận diện đối tượng và phân khúc trên cả GPU và CPU\n","- Độ tự tin của bounding box trong mô hình YOLO được dựa trên kết quả của hàm logistic regression. Mỗi bounding box được dự đoán kèm với một xác suất được tính thông qua hàm sigmoid.\n","    - YoloV8 tính độ tự tin cho bounding box bằng cách sử dụng 2 giá trị:\n","        - Giá trị xác xuất (probality): Cho biết khả năng bounding box chứa một đối tượng thực sự. Được tính bằng cách sử dụng một neural network phụ với input là đầu ra của các lớp detection network và dự đoán xác suất cho mỗi bounding box.\n","        - Giá trị IOU: Giá trị này cho biết mức độ trùng khớp của bounding box với bounding box của đối tượng thực tế. Được tính bằng cách so sánh bounding box dự đoán với bounding box của đối tượng thực tế.\n","                + IOU = (area of intersection)/(area of union)\n","                + confidence = probability * IOU\n","- Giá trị tự tin được sử dụng để lọc ra các bounding box không chứa đối tượng thực sự. Độ tự tin thấp hơn ngưỡng nhất định sẽ bị loại bỏ (mặc định 0.5)"]},{"cell_type":"markdown","metadata":{"id":"THeIJ6UaMbT8"},"source":["Nhận diện:"]},{"cell_type":"markdown","metadata":{"id":"JdU6RYhoMbT8"},"source":["<h3> Pytesseract: </h3 >\n","-   Mô tả: Pytesseract là một thư viện Python dựa trên Tesseract, một hệ thống nhận diện ký tự quốc tế.\n","-   Cách hoạt động: Pytesseract nhận diện văn bản trong ảnh bằng cách chuyển đổi ảnh thành ảnh đen trắng để tăng cường độ tương phản. Sau đó, nó sử dụng Tesseract để phân tích các thành phần văn bản và nhận diện ký tự trong ảnh. Đầu ra bao gồm văn bản được nhận diện và các thông tin khác như tọa độ của vùng văn bản.\n","-   Điểm vượt trội: Pytesseract có khả năng nhận diện văn bản từ ảnh một cách nhanh chóng và hiệu quả. Nó là một công cụ mã nguồn mở và dễ sử dụng trong các ứng dụng yêu cầu nhận diện ký tự.\n","<h3> EasyOCR: </h3 >\n","<br>\n","-   Mô tả: EasyOCR là một thư viện Python được thiết kế để nhận diện văn bản từ ảnh sử dụng mô hình học máy.\n","-   Cách hoạt động: EasyOCR sử dụng mô hình học máy trước đó được huấn luyện để nhận diện văn bản. Ảnh đầu vào được chia thành các vùng với văn bản có thể xuất hiện. Mỗi vùng sau đó được đưa vào mô hình để nhận diện ký tự và từ.\n","-   Điểm vượt trội: EasyOCR cung cấp sự linh hoạt với khả năng nhận diện văn bản ở nhiều ngôn ngữ khác nhau. Nó giúp tự động nhận diện và trích xuất thông tin từ hình ảnh, hỗ trợ nhiều ứng dụng như quét tài liệu, OCR tự động, v.v."]},{"cell_type":"markdown","metadata":{"id":"Rl7XZ3rSMbT8"},"source":["# 6. Cài đặt, tinh chỉnh tham số"]},{"cell_type":"markdown","metadata":{"id":"OJbRYEn7MbT8"},"source":["- Tham số file mydata.yaml để train:\n","    - path: đường dẫn đến tập train\n","        /content/drive/MyDrive/Dataset_CS114/CS114/Dataset\n","    - train: images/train\n","    - val: images/val\n","    - names:\n","        0: Listening\n","        1: Name\n","        2: Reading\n","        3: Speaking\n","        4: Test_date\n","        5: Valid_date\n","        6: Writing\n","-  Tinh chỉnh tham số xử lí ảnh: (Phần demo Google Colab)\n","    -"]},{"cell_type":"markdown","metadata":{"id":"ZZVeweScMbT9"},"source":["# 7. Đánh giá model, kết luận"]},{"cell_type":"markdown","metadata":{"id":"OCdkB9j8MbT9"},"source":["### 7.1 Đánh giá model"]},{"cell_type":"markdown","metadata":{"id":"wRScOTmGMbT9"},"source":["- Dựa vào Accuracy của 2 model PyTesseract và Easy_OCR\n","- Accuracy được tính theo từng bounding box: (Kết quả đọc đúng * 100 / Tổng số)\n","- Ví dụ: Có 20 ảnh -> 20  bounding box chứa name, trong đó model nhận diện chính xác 18 name thì accuracy sẽ được tính: <br>\n","(18*100)/20 = 0.9"]},{"cell_type":"markdown","metadata":{"id":"9OdFM_hYMbT9"},"source":["- Kết quả sau khi thực hiện với dataset của nhóm:\n","![image.png](attachment:image.png)"]},{"cell_type":"markdown","metadata":{"id":"nX_N7E_EMbT9"},"source":["=> Kết quả trên cho thấy việc sử dụng Easy_OCR nhận diện tốt hơn so với PyTesseract"]},{"cell_type":"markdown","metadata":{"id":"bc3NPLt8MbT9"},"source":["### 7.2 Kết luận"]},{"cell_type":"markdown","metadata":{"id":"s442kweJMbT9"},"source":["Qua quá trình thực hiện đồ án, nhóm đã thành công trong việc đọc được cơ bản các thông tin trên chứng chỉ TOEIC về cả thông tin chữ lẫn thông tin số. Các thành viên cũng đã tìm hiểu được cách ứng dụng các mô hình máy học vào thực tế cũng như các bước cơ bản để giải một bài toán machine learning. Toàn bộ quy trình từ thu thập dữ liệu đến xử lý cũng như gán nhãn, nhóm đều dành thời gian để tự tay làm. Không chỉ có vậy, nhóm còn bước đầu tìm hiểu về object detection cũng như text recognition và cách cài đặt chúng. Tuy nhiên, với kiến thức và kinh nghiệm còn non nớt cũng như thời gian có hạn, đồ án của nhóm vẫn còn nhiều vấn đề chưa thể giải quyết được. Nhóm chúng em hi vọng thầy có thể đưa ra những lời góp ý chân thành nhất để đồ án chúng em có thể hoàn thiện hơn."]},{"cell_type":"markdown","metadata":{"id":"QrAOf5TFMbT-"},"source":["### 7.3 Hướng phát triển\n","Nhóm sẽ tăng cường độ chính xác của mô hình khi thực hiện trích xuất thông tin với ảnh được chụp ở nhiều điều kiện khác nhau. Tìm kiếm một model có thể nhận diện được một cách chính xác nhất các thông tin do mô hình được nhóm sử dụng vẫn còn nhận diện sai một vài trường hợp. Sau khi hoàn thành tốt được đề tài, nhóm sẽ phát triển hệ thống tự động nhận diện các loại chứng chỉ khác như IELTS, TOEFL, …. . và nhiều loại chứng chỉ hơn nữa."]},{"cell_type":"markdown","metadata":{"id":"II6t5IB_MbT-"},"source":["TÀI LIỆU THAM KHẢO\n","- YOLOv8 https://docs.ultralytics.com/\n","- Pytesseract https://pypi.org/project/pytesseract/\n","- https://github.com/lphuong304/CS114.L21/blob/main/FINAL_PROJECT/DemoFinalProject.ipynb"]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":0}